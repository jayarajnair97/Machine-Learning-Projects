# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
from wordcloud import WordCloud

# Load the dataset
ecommerce_data = pd.read_json('fashion_products_dataset.json')
df = ecommerce_data

df.head()

# Display basic information about the dataset
print("Dataset Information:")
print(df.info())

# Visualize missing values
plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

# Explore product categories and brands
plt.figure(figsize=(12, 6))
sns.countplot(x='category', data=df, order=df['category'].value_counts().index)
plt.title('Distribution of Products across Categories')
plt.xticks(rotation=45, ha='right')
plt.show()

plt.figure(figsize=(12, 6))
top_brands = df['brand'].value_counts().index[:20]
sns.countplot(x='brand', data=df[df['brand'].isin(top_brands)], order=top_brands)
plt.title('Distribution of Products across Top 20 Brands')
plt.xticks(rotation=45, ha='right')
plt.show()


# Analyze pricing trends and discount strategies
plt.figure(figsize=(12, 6))
sns.histplot(df['actual_price'], bins=30, kde=True)
plt.title('Distribution of Actual Prices')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(df['discount'], bins=30, kde=True)
plt.title('Distribution of Discounts')
plt.show()

# Explore average ratings
plt.figure(figsize=(12, 6))
sns.countplot(x='average_rating', data=df)
plt.title('Distribution of Average Ratings')
plt.show()

# Text Classification (Example: Predicting if a product is out of stock)
# Assuming 'out_of_stock' is the target variable
X_text_classification = df['description'].fillna('').astype(str)
y_text_classification = df['out_of_stock'].astype(int)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_text_classification, y_text_classification, test_size=0.2, random_state=42)

# Text vectorization using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Text classification using Naive Bayes
classifier = MultinomialNB()
classifier.fit(X_train_tfidf, y_train)
y_pred = classifier.predict(X_test_tfidf)

# Evaluate the text classification model
print("\nText Classification Report:")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

# Word Cloud for positive and negative sentiments (eg;Assuming 'out_of_stock' as a binary sentiment)
positive_text = ' '.join(df[df['out_of_stock'] == 1]['description'].fillna('').astype(str))
negative_text = ' '.join(df[df['out_of_stock'] == 0]['description'].fillna('').astype(str))

wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_text)
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_text)

plt.figure(figsize=(25, 18))
plt.subplot(1, 2, 1)
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Out of Stock Products')
plt.show()


plt.figure(figsize=(25, 18))
plt.subplot(1, 2, 2)
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for In Stock Products')
plt.show()

# Additional Text Analysis Word frequency analysis)
from sklearn.feature_extraction.text import CountVectorizer

# Count Vectorization
count_vectorizer = CountVectorizer(stop_words='english', max_features=20)
X_count_vectorized = count_vectorizer.fit_transform(X_text_classification)

# Word Frequency Analysis
word_frequency_df = pd.DataFrame(X_count_vectorized.toarray(), columns=count_vectorizer.get_feature_names_out())
word_frequency_sum = word_frequency_df.sum().sort_values(ascending=False)

# Display the top 20 words by frequency
plt.figure(figsize=(12, 6))
sns.barplot(x=word_frequency_sum.index[:20], y=word_frequency_sum.values[:20])
plt.title('Top 20 Words by Frequency in Product Descriptions')
plt.xticks(rotation=45, ha='right')
plt.show()




